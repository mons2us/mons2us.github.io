---
layout: post
title:  "An Architecture Combining Convolutional Neural Network and Support Vector Machine for Image Classification"
date:   2020-10-28 14:25:52
author: mons2us
categories: Paper-Reproduction Deeplearning
tags: deeplearning svm
---
> 이 글은 논문 \<An Architecture Combining Convolutional Neural Network and Support Vector Machine for Image Classification\>를 이해하고자 다양한 소스로부터 학습한 내용을 정리한 글입니다. 혹시 내용 중 틀린 부분이 있거나 궁금한 사항이 있으신 경우 댓글을 남겨주시면 최선을 다해 소통하겠습니다.<br>
위 논문을 재현(reproduce)한 결과물은 제 [깃허브](https://github.com/mons2us/paper_reproduction/tree/master/Autoencoding-Variational-Bayes)를 참고하시기 바랍니다.

# Overview
우리는 많은 경우 classification을 위한 딥러닝 모델에서 마지막 layer(많은 경우 fully-connected layer)를 가지고 softmax cross entropy를 계산합니다. Softmax cross entropy는 직관적이고 효과적이며, 무엇보다 연산이 빠릅니다.
하지만 "softmax가 가장 낫다"라는 논리에 반박하기 위한 연구도 있습니다. 대표적으로 \<Deep Learning using Linear Support Vector Machines, Yichuan Tang, 2013\>의 저자는 위 softmax 대신에 linear support vector machine(L2-SVM)을 집어넣어 MNIST, CIFAR-10 등의 데이터셋 분류 문제에서 더 나은 성능을 얻은 바 있습니다. (하지만 뒤에 반전이 있습니다..)
"분류 모델에는 (거의) 무조건 softmax"라고 생각했던지라 적잖이 놀라운 결과였습니다. 무엇보다 loss를 학습하기 위한 최적의 목적함수가 데이터에 따라, 상황에 따라 다를 수 있다는 것을 다시 한 번 깨닫게 되었죠.
<br><br>
본 포스트에서 소개할 논문 \<An Architecture Combining Convolutional Neural Network and Support Vector Machine for Image Classification\>는 위 \<Deep Learning using Linear Support Vector Machines\>의 후속 논문입니다.
앞선 논문을 CNN 모델의 관점에서 좀 더 자세하게 분석한 결과라고 할 수 있는데 문제는... \<Deep Learning using Linear Support Vector Machines\>는 "CNN+SVM이 SNN+Softmax보다 낫다"고 주장한 반면 \<An Architecture Combining Convolutional Neural Network and Support Vector Machine for Image Classification\>의 실험 결과는 그와 반대입니다. 약간 웃긴 상황이기는 하나 어쨌든 후자 논문은 conclusion에서 아래와 같이 말합니다.<br>
Despite its contradiction to the findings in [11], quantitatively speaking, the test accuracies of CNN-Softmax and CNN-SVM are almost the same with the related study.
It is hypothesized that with data preprocessing and a relatively more sophisticated base CNN model, the results in [11] shall be reproduced.
<br>
소개드리는 논문에서의 CNN은 굉장히 심플한 2-layer Conv Layer을 이용하고 있고, \<Deep Learning using Linear Support Vector Machines\>에서는 좀 더 정교한 모델을 썼기에 위와 같은 차이가 발생했다고 하는 듯 합니다.
근데 CNN모델을 더 정교화하면 softmax를 이용한 결과도 상향되지 않을까요? ㅎㅎ 이쯤 되니 \<Deep Learning using Linear Support Vector Machines\> 논문의 실험에 대해 더 궁금증이 생깁니다.
어쨌든 본 논문은 내용을 순차적으로 다룬 후에 실험에 사용한 코드 구현을 수행하도록 하겠습니다.
<br><br>

# 왜 SVM인가?
논문 \<An Architecture Combining Convolutional Neural Network and Support Vector Machine for Image Classification\>의 저자는 Introduction 부분에서 아래와 같이 말합니다.<br>
> However, there have been studies conducted that takes a look at an alternative to softmax function for classification – the support vector machine (SVM). The aforementioned studies have
claimed that the use of SVM in an artificial neural network (ANN) architecture produces a relatively better results than the use of the conventional softmax function. Of course, there is a drawback to
this approach, and that is the restriction to binary classification.<br>

즉 binary classfication 문제에 한해서 softmax보다 svm이 나은 결과를 가져올 수 있다는 내용입니다.
SVM은 최적의 초평면(hyperplane)을 찾아 두 개의 클래스를 나누는 방법론이자 그러한 문제에 굉장히 효과적인 방법론이고, 그렇기에 binary classification의 문제에 한정되어 softmax보다 낫다고 주장합니다.
만약 클래스가 여러개인 경우는 one vs all 문제가 되어, target class가 1, 나머지는 모두 -1이 됩니다. 이 경우에는 softmax가 성능이 좋을 것이라 생각됩니다만, 어쨌든 논문을 계속 살펴보겠습니다.
<br><br>

# 방법론
우선 논문의 실험을 위해 가장 대표적 분류 데이터인 MNIST digit dataset을 사용합니다. 하지만 이는 너무 쉬운 데이터셋으로서 현대의 Computer Vision을 대표하기엔 어려운 데이터입니다. 매우 얕은 구조로도 99% 정확도는 쉽게 달성하기 때문입니다.
그래서 논문의 저자는 Fashion-MNIST를 추가적으로 실험에 이용하였습니다. 데이터 분포는 아래와 같습니다.<br>
<<데이터구조 그림>><br>


# SVM이 무엇인가?
그렇다면 Support Vector Machine(SVM)이 실제로 어떤 방법론인지 이론적인 부분을 살펴보도록 하겠습니다. SVM은 Vapnik에 의하여 binary classification을 위해 고안된 방법론으로서, 그 목적은 hyper parameter인 f(w, x)를 찾아 데이터셋의 두 클래스를 분류하는 데에 있습니다. 아래 수식을 최적화하는 방향으로 w를 학습함

이 때 L1에 비해 L2-SVM이 좀 더 안정적인 성능을 냄 (이유?)

## Hinge Loss


## Triplet Loss

# CNN
Convoltional Neural Network (CNN)은 보통의 뉴럴 네트워크와 기본적으로 동일합니다. 학습이 가능한 뉴런들을 가지고 인풋(이미지)을 받은 후에, 내적을 하고 다양한 비선형성(ReLU, Sigmoid 등)을 추가합니다.
참고로 Convolution이라는 용어는 kernel(filter)들이 matrix 형태로써 이미지의 각 픽셀값을 합성곱(Convolution)한 결과를 이용하기 때문에 지어진 이름입니다.
CNN을 보통 이미지 연산에 사용하기는 하지만, 이미지 분야 외에도 음성, 문자, 시계열 등 다양한 데이터에 사용하는 딥러닝 기법입니다.<br>
<<구조 그림>><br>
위 그림이 CNN을 설명하는 대표적인 도식입니다. 대부분 잘 아시는 내용이기에, 더 자세한 내용은 CNN을 제대로 다루는 포스트에서 설명하도록 하겠습니다.
어찌 됐든 보편적인  Image Classification 문제에서 우리는 1) 어떤 이미지를 받고 2) CNN에 태운 후에  3) Fully connected layer(Dense layer)에 태워 결과물을 벡터 형태로 만듭니다.
이 때 class 개수가 80이라면 최종적인 벡터의 개수도 80이 될 것이고, 그걸 가지고 softmax 함수에 태워서 cross entropy를 계산하는 것이 보편적인 softmax-cross entropy입니다.<br><br>
본 논문에서 사용되는 CNN 구조는 아래와 같습니다.
<br>
> (1) INPUT: 32 × 32 × 1<br>
(2) CONV5: 5 × 5 size, 32 filters, 1 stride<br>
(3) ReLU: max(0,hθ(x))<br>
(4) POOL: 2 × 2 size, 1 stride<br>
(5) CONV5: 5 × 5 size, 64 filters, 1 stride<br>
(6) ReLU: max(0,hθ(x))<br>
(7) POOL: 2 × 2 size, 1 stride<br>
(8) FC: 1024 Hidden Neurons<br>
(9) DROPOUT: p = 0.5<br>
(10) FC: 10 Output Classes<br>

위 과정 중 (10)번의 Fully Connected Layer를 거쳐 나온 길이 10의 벡터가 결국 주어진 이미지가 특정 클래스 C에 속할 Confidence를 나타내고, 이를 이용해 분류 문제의 loss를 계산합니다. 이 loss를 정의할 때
(1) Softmax
(2) SVM
을 사용하여 실험을 진행하게 됩니다.<br>
설정된 하이퍼 파라미터는 아래와 같습니다.<br>
<<hyperparameter>><br>

실제 실험에 사용하기 위한 CNN은 torch로 구현하였고, 아래와 같습니다.

중요한 것은, CNN을 통과한 이후에 클래스가 예측되고 나서 이 값을 가지고 어떻게 Loss를 계산하는가 입니다. Softmax는 당연히 softmax cross-entropy를 가지고 Loss를 계산하는데, 아래와 같습니다.

SVM은 위에 나온 그래프에서 알 수 있듯이, 공간에서 두 클래스의 margin을 어쩌고.. 이 때 hinge loss라는 개념이 등장합니다.

<hinge loss>

그러면 softmax cross entropy 대신에 hinge loss를 이용해 클래스를 구분하도록 하면 결국 SVM을 이용해 ~~하는 것이겠습니다. 구현 코드는 아래와 같습니다.

